{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40edb3c4",
   "metadata": {},
   "source": [
    "## 6.4 Algoritmo de Aprendizado de Árvore de Decisão\n",
    "- Encontrando a melhor divisão para uma coluna\n",
    "- Encontrando a melhor divisão para todo o conjunto de dados\n",
    "- Critérios de parada\n",
    "- Algoritmo de aprendizado de árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install_xgboost",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalando XGBoost (execute esta célula apenas uma vez)\n",
    "# Descomente a linha abaixo se precisar instalar\n",
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0afcda96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Importando bibliotecas de machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Importando XGBoost - biblioteca de Gradient Boosting\n",
    "# XGBoost é uma implementação otimizada de árvores de decisão em ensemble\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preparacao_dados",
   "metadata": {},
   "source": [
    "### Preparando Dados Reais para XGBoost\n",
    "Vamos carregar o dataset de crédito e preparar para usar com XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "carregar_dados",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dataset de crédito\n",
    "data_url = 'https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-06-trees/CreditScoring.csv'\n",
    "df = pd.read_csv(data_url)\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "# Mapeando valores categóricos\n",
    "df.status = df.status.map({1: 'ok', 2: 'default', 0: 'unk'})\n",
    "df.home = df.home.map({1: 'rent', 2: 'owner', 3: 'private', 4: 'ignore', 5: 'parents', 6: 'other', 0: 'unk'})\n",
    "df.marital = df.marital.map({1: 'single', 2: 'married', 3: 'widow', 4: 'separated', 5: 'divorced', 0: 'unk'})\n",
    "df.records = df.records.map({1: 'no', 2: 'yes', 0: 'unk'})\n",
    "df.job = df.job.map({1: 'fixed', 2: 'partime', 3: 'freelance', 4: 'others', 0: 'unk'})\n",
    "\n",
    "# Removendo valores desconhecidos e preparando target\n",
    "df = df[df.status != 'unk'].reset_index(drop=True)\n",
    "for c in ['income', 'assets', 'debt']:\n",
    "    df[c] = df[c].replace(to_replace=99999999, value=np.nan)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dividir_dados",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo em treino, validação e teste\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=11)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=11)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "# Preparando target (y)\n",
    "y_train = (df_train.status == 'default').astype('int').values\n",
    "y_val = (df_val.status == 'default').astype('int').values\n",
    "y_test = (df_test.status == 'default').astype('int').values\n",
    "\n",
    "# Removendo coluna target\n",
    "del df_train['status']\n",
    "del df_val['status']\n",
    "del df_test['status']\n",
    "\n",
    "print(f'Treino: {len(df_train)} amostras')\n",
    "print(f'Validação: {len(df_val)} amostras')\n",
    "print(f'Teste: {len(df_test)} amostras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preparar_features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando features com DictVectorizer\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dicts = df_train.fillna(0).to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val.fillna(0).to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "print(f'Número de features: {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preparar_xgboost",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando dados no formato DMatrix do XGBoost\n",
    "features = list(dv.get_feature_names_out())\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=features)\n",
    "dval = xgb.DMatrix(X_val, label=y_val, feature_names=features)\n",
    "\n",
    "print('Dados preparados para XGBoost!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exemplo1",
   "metadata": {},
   "source": [
    "### Exemplo 1: Dataset Simples com Ativos\n",
    "Vamos criar um dataset de exemplo com informações sobre ativos e status de pagamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a27ff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando dados de exemplo: [ativos, status]\n",
    "# 'default' = inadimplente, 'ok' = pagamento em dia\n",
    "dados = [\n",
    "    [8000, 'default'],\n",
    "    [2000, 'default'],\n",
    "    [   0, 'default'],\n",
    "    [5000, 'ok'],\n",
    "    [5000, 'ok'],\n",
    "    [4000, 'ok'],\n",
    "    [9000, 'ok'],\n",
    "    [3000, 'default'],\n",
    "]\n",
    "\n",
    "df_exemplo = pd.DataFrame(dados, columns=['ativos', 'status'])\n",
    "df_exemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordenacao",
   "metadata": {},
   "source": [
    "### Ordenando os Dados\n",
    "Para encontrar os melhores pontos de divisão, ordenamos os dados pela coluna de ativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38420afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenando pelo valor dos ativos para visualizar melhor\n",
    "df_exemplo.sort_values('ativos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thresholds",
   "metadata": {},
   "source": [
    "### Definindo Limiares (Thresholds)\n",
    "Vamos testar diferentes valores de corte para dividir os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e53392f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limiares a serem testados (valores únicos dos ativos)\n",
    "Ts = [0, 2000, 3000, 4000, 5000, 8000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "teste_divisao",
   "metadata": {},
   "source": [
    "### Testando uma Divisão Específica\n",
    "Exemplo: dividindo os dados no limiar T = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "035494f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "T = 4000\n",
    "# Dividindo: esquerda (<=T) e direita (>T)\n",
    "df_esquerda = df_exemplo[df_exemplo.ativos <= T]\n",
    "df_direita = df_exemplo[df_exemplo.ativos > T]\n",
    "\n",
    "display(df_esquerda)\n",
    "print(\"Proporção de cada classe no grupo esquerdo:\")\n",
    "print(df_esquerda.status.value_counts(normalize=True))\n",
    "\n",
    "display(df_direita)\n",
    "print(\"Proporção de cada classe no grupo direito:\")\n",
    "print(df_direita.status.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "todos_limiares",
   "metadata": {},
   "source": [
    "### Testando Todos os Limiares\n",
    "Agora vamos testar todos os limiares possíveis para encontrar a melhor divisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db247984",
   "metadata": {},
   "outputs": [],
   "source": [
    "for T in Ts:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Testando limiar T = {T}\")\n",
    "    print('='*50)\n",
    "    \n",
    "    df_esquerda = df_exemplo[df_exemplo.ativos <= T]\n",
    "    df_direita = df_exemplo[df_exemplo.ativos > T]\n",
    "    \n",
    "    print(f\"\\nGrupo ESQUERDA (ativos <= {T}):\")\n",
    "    display(df_esquerda)\n",
    "    print(\"Proporções:\")\n",
    "    print(df_esquerda.status.value_counts(normalize=True))\n",
    "    \n",
    "    print(f\"\\nGrupo DIREITA (ativos > {T}):\")\n",
    "    display(df_direita)\n",
    "    print(\"Proporções:\")\n",
    "    print(df_direita.status.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exemplo2",
   "metadata": {},
   "source": [
    "### Exemplo 2: Dataset com Múltiplas Features\n",
    "Agora vamos adicionar uma segunda coluna (dívidas) para tornar o problema mais realista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84fd3576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados com duas features: ativos e dívidas\n",
    "dados = [\n",
    "    [8000, 3000, 'default'],\n",
    "    [2000, 1000, 'default'],\n",
    "    [   0, 1000, 'default'],\n",
    "    [5000, 1000, 'ok'],\n",
    "    [5000, 1000, 'ok'],\n",
    "    [4000, 1000, 'ok'],\n",
    "    [9000,  500, 'ok'],\n",
    "    [3000, 2000, 'default'],\n",
    "]\n",
    "\n",
    "df_exemplo = pd.DataFrame(dados, columns=['ativos', 'dividas', 'status'])\n",
    "df_exemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordenacao_dividas",
   "metadata": {},
   "source": [
    "### Ordenando por Dívidas\n",
    "Vamos ver como os dados ficam quando ordenados pela coluna de dívidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "963ad9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenando pela coluna de dívidas\n",
    "df_exemplo.sort_values('dividas')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thresholds_multiplos",
   "metadata": {},
   "source": [
    "### Definindo Limiares para Múltiplas Features\n",
    "Agora temos limiares diferentes para cada feature (ativos e dívidas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47927b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário com limiares para cada feature\n",
    "limiares = {\n",
    "    'ativos': [0, 2000, 3000, 4000, 5000, 8000],\n",
    "    'dividas': [500, 1000, 2000]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "teste_todas_features",
   "metadata": {},
   "source": [
    "### Testando Todas as Features e Limiares\n",
    "Este é o processo completo de busca pela melhor divisão:\n",
    "- Para cada feature (ativos, dívidas)\n",
    "- Para cada limiar possível\n",
    "- Calculamos a pureza de cada divisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "324bb45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature, Ts in limiares.items():\n",
    "    print('\\n' + '#'*60)\n",
    "    print(f'TESTANDO FEATURE: {feature.upper()}')\n",
    "    print('#'*60)\n",
    "    \n",
    "    for T in Ts:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Limiar: {feature} <= {T}\")\n",
    "        print('='*50)\n",
    "        \n",
    "        # Dividindo os dados\n",
    "        df_esquerda = df_exemplo[df_exemplo[feature] <= T]\n",
    "        df_direita = df_exemplo[df_exemplo[feature] > T]\n",
    "\n",
    "        print(f\"\\nGrupo ESQUERDA ({feature} <= {T}):\")\n",
    "        display(df_esquerda)\n",
    "        if len(df_esquerda) > 0:\n",
    "            print(\"Proporções:\")\n",
    "            print(df_esquerda.status.value_counts(normalize=True))\n",
    "        \n",
    "        print(f\"\\nGrupo DIREITA ({feature} > {T}):\")\n",
    "        display(df_direita)\n",
    "        if len(df_direita) > 0:\n",
    "            print(\"Proporções:\")\n",
    "            print(df_direita.status.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusao",
   "metadata": {},
   "source": [
    "### Conclusão\n",
    "\n",
    "O algoritmo de árvore de decisão funciona da seguinte forma:\n",
    "\n",
    "1. **Para cada feature** (ativos, dívidas, etc.)\n",
    "2. **Para cada limiar possível** (valores únicos da feature)\n",
    "3. **Divide os dados** em dois grupos: esquerda (<=limiar) e direita (>limiar)\n",
    "4. **Calcula a impureza** de cada divisão (usando Gini, Entropia, etc.)\n",
    "5. **Escolhe a melhor divisão** (aquela que mais reduz a impureza)\n",
    "6. **Repete o processo** recursivamente para cada subgrupo\n",
    "7. **Para quando** atingir um critério de parada (profundidade máxima, número mínimo de amostras, etc.)\n",
    "\n",
    "A melhor divisão é aquela que cria grupos mais \"puros\" (homogêneos), ou seja, onde a maioria dos exemplos pertence à mesma classe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impureza",
   "metadata": {},
   "source": [
    "### Calculando a Impureza (Índice de Gini)\n",
    "\n",
    "O Índice de Gini mede a impureza de um grupo:\n",
    "- Gini = 0: grupo perfeitamente puro (todos da mesma classe)\n",
    "- Gini = 0.5: grupo perfeitamente impuro (50% de cada classe)\n",
    "\n",
    "Fórmula: Gini = 1 - (p₁² + p₂²)\n",
    "onde p₁ e p₂ são as proporções de cada classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "funcao_gini",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_impureza_gini(df):\n",
    "    \"\"\"\n",
    "    Calcula o índice de Gini para medir a impureza de um grupo\n",
    "    Quanto menor o Gini, mais puro é o grupo\n",
    "    \"\"\"\n",
    "    # Contando quantos exemplos temos de cada classe\n",
    "    contagens = df.status.value_counts(normalize=True)\n",
    "    \n",
    "    # Calculando Gini = 1 - soma(p²) para cada classe\n",
    "    gini = 1 - (contagens ** 2).sum()\n",
    "    \n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "teste_gini",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando o cálculo de Gini no dataset completo\n",
    "print(f\"Impureza do dataset completo: {calcular_impureza_gini(df_exemplo):.4f}\")\n",
    "\n",
    "# Testando com uma divisão específica\n",
    "T = 1500\n",
    "df_esquerda = df_exemplo[df_exemplo.dividas <= T]\n",
    "df_direita = df_exemplo[df_exemplo.dividas > T]\n",
    "\n",
    "print(f\"\\nDivisão em dívidas <= {T}:\")\n",
    "print(f\"Impureza grupo esquerdo: {calcular_impureza_gini(df_esquerda):.4f}\")\n",
    "print(f\"Impureza grupo direito: {calcular_impureza_gini(df_direita):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ganho_informacao",
   "metadata": {},
   "source": [
    "### Calculando o Ganho de Informação\n",
    "\n",
    "O ganho de informação mede o quanto uma divisão reduz a impureza:\n",
    "\n",
    "Ganho = Impureza_antes - Impureza_depois\n",
    "\n",
    "Onde Impureza_depois é a média ponderada das impurezas dos grupos resultantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "funcao_ganho",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_ganho_informacao(df, df_esquerda, df_direita):\n",
    "    \"\"\"\n",
    "    Calcula o ganho de informação de uma divisão\n",
    "    Quanto maior o ganho, melhor é a divisão\n",
    "    \"\"\"\n",
    "    # Impureza antes da divisão\n",
    "    impureza_antes = calcular_impureza_gini(df)\n",
    "    \n",
    "    # Tamanho total e dos grupos\n",
    "    n = len(df)\n",
    "    n_esquerda = len(df_esquerda)\n",
    "    n_direita = len(df_direita)\n",
    "    \n",
    "    # Impureza depois da divisão (média ponderada)\n",
    "    impureza_depois = (n_esquerda / n) * calcular_impureza_gini(df_esquerda) + \\\n",
    "                      (n_direita / n) * calcular_impureza_gini(df_direita)\n",
    "    \n",
    "    # Ganho de informação\n",
    "    ganho = impureza_antes - impureza_depois\n",
    "    \n",
    "    return ganho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "busca_melhor_divisao",
   "metadata": {},
   "source": [
    "### Encontrando a Melhor Divisão\n",
    "\n",
    "Agora vamos implementar a função que busca a melhor divisão possível:\n",
    "- Testa todas as features\n",
    "- Testa todos os limiares possíveis\n",
    "- Retorna a divisão com maior ganho de informação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "funcao_melhor_divisao",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_melhor_divisao(df):\n",
    "    \"\"\"\n",
    "    Encontra a melhor divisão testando todas as features e limiares\n",
    "    Retorna: (melhor_feature, melhor_limiar, melhor_ganho)\n",
    "    \"\"\"\n",
    "    melhor_ganho = -1\n",
    "    melhor_feature = None\n",
    "    melhor_limiar = None\n",
    "    \n",
    "    # Para cada feature numérica\n",
    "    for feature in ['ativos', 'dividas']:\n",
    "        # Pegando valores únicos como limiares possíveis\n",
    "        limiares = df[feature].unique()\n",
    "        \n",
    "        # Testando cada limiar\n",
    "        for T in limiares:\n",
    "            # Dividindo os dados\n",
    "            df_esquerda = df[df[feature] <= T]\n",
    "            df_direita = df[df[feature] > T]\n",
    "            \n",
    "            # Ignorando divisões que deixam um lado vazio\n",
    "            if len(df_esquerda) == 0 or len(df_direita) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Calculando o ganho\n",
    "            ganho = calcular_ganho_informacao(df, df_esquerda, df_direita)\n",
    "            \n",
    "            # Atualizando se encontramos um ganho melhor\n",
    "            if ganho > melhor_ganho:\n",
    "                melhor_ganho = ganho\n",
    "                melhor_feature = feature\n",
    "                melhor_limiar = T\n",
    "    \n",
    "    return melhor_feature, melhor_limiar, melhor_ganho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "teste_melhor_divisao",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrando a melhor divisão para nosso dataset\n",
    "feature, limiar, ganho = encontrar_melhor_divisao(df_exemplo)\n",
    "\n",
    "print(f\"Melhor divisão encontrada:\")\n",
    "print(f\"Feature: {feature}\")\n",
    "print(f\"Limiar: {limiar}\")\n",
    "print(f\"Ganho de informação: {ganho:.4f}\")\n",
    "\n",
    "# Mostrando os grupos resultantes\n",
    "df_esquerda = df_exemplo[df_exemplo[feature] <= limiar]\n",
    "df_direita = df_exemplo[df_exemplo[feature] > limiar]\n",
    "\n",
    "print(f\"\\nGrupo ESQUERDO ({feature} <= {limiar}):\")\n",
    "print(df_esquerda)\n",
    "print(f\"Distribuição: {df_esquerda.status.value_counts().to_dict()}\")\n",
    "\n",
    "print(f\"\\nGrupo DIREITO ({feature} > {limiar}):\")\n",
    "print(df_direita)\n",
    "print(f\"Distribuição: {df_direita.status.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusao_final",
   "metadata": {},
   "source": [
    "### Conclusão Final\n",
    "\n",
    "Implementamos os componentes principais do algoritmo de árvore de decisão:\n",
    "\n",
    "1. **Cálculo de Impureza (Gini)**: Mede quão \"misturado\" está um grupo\n",
    "2. **Ganho de Informação**: Mede o quanto uma divisão melhora a pureza\n",
    "3. **Busca pela Melhor Divisão**: Testa todas as possibilidades e escolhe a melhor\n",
    "\n",
    "**Como a árvore completa é construída:**\n",
    "\n",
    "1. Começa com todos os dados\n",
    "2. Encontra a melhor divisão\n",
    "3. Divide os dados em dois grupos\n",
    "4. Repete o processo recursivamente para cada grupo\n",
    "5. Para quando atingir um critério de parada:\n",
    "   - Profundidade máxima atingida\n",
    "   - Número mínimo de amostras\n",
    "   - Grupo já está puro\n",
    "   - Nenhuma divisão melhora a pureza\n",
    "\n",
    "**Vantagens das Árvores de Decisão:**\n",
    "- Fáceis de interpretar e visualizar\n",
    "- Não precisam de normalização dos dados\n",
    "- Lidam bem com features categóricas e numéricas\n",
    "- Capturam relações não-lineares\n",
    "\n",
    "**Desvantagens:**\n",
    "- Propensas a overfitting\n",
    "- Instáveis (pequenas mudanças nos dados podem mudar muito a árvore)\n",
    "- Podem criar árvores muito complexas\n",
    "\n",
    "**Solução:** Usar métodos de ensemble como Random Forest e Gradient Boosting!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
